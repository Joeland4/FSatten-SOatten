Args in experiment:
Namespace(activation='gelu', affine=0, batch_size=128, c_out=8, checkpoints='./checkpoints/', d_ff=256, d_layers=1, d_model=128, d_ortho=8, data='custom', data_path='exchange_rate.csv', dec_in=8, decomposition=0, des='Exp', devices='0,1,2,3', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', embed_type=0, enc_in=8, factor=3, fc_dropout=0.05, features='M', freq='h', gpu=0, head_dropout=0.0, individual=0, is_training=1, itr=1, kernel_size=25, label_len=48, learning_rate=0.0001, loss='mse', lradj='TST', model='PatchTST_orthoConv', model_id='Exchange_96_96', moving_avg=25, n_heads=16, num_workers=10, output_attention=False, padding_patch='end', patch_len=16, patience=10, pct_start=0.3, pred_len=336, random_seed=2021, revin=1, root_path='/data1/mazc/whxProject/Dataset/', seq_len=96, stride=8, subtract_last=0, target='OT', test_flop=False, train_epochs=40, use_amp=False, use_gpu=True, use_multi_gpu=False)
Use GPU: cuda:0
>>>>>>>start training : Exchange_96_96_PatchTST_orthoConv_custom_ftM_sl96_ll48_pl336_dm128_nh16_el2_dl1_df256_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4880
val 425
test 1182
Epoch: 1 cost time: 4.010504722595215
Epoch: 1, Steps: 38 | Train Loss: 0.5042733 Vali Loss: 0.4806480 Test Loss: 0.3788886
Validation loss decreased (inf --> 0.480648).  Saving model ...
Updating learning rate to 5.642716179699798e-06
Epoch: 2 cost time: 1.5917136669158936
Epoch: 2, Steps: 38 | Train Loss: 0.4904053 Vali Loss: 0.4642744 Test Loss: 0.3635718
Validation loss decreased (0.480648 --> 0.464274).  Saving model ...
Updating learning rate to 1.0458426533505524e-05
Epoch: 3 cost time: 1.7563304901123047
Epoch: 3, Steps: 38 | Train Loss: 0.4727678 Vali Loss: 0.4476484 Test Loss: 0.3430539
Validation loss decreased (0.464274 --> 0.447648).  Saving model ...
Updating learning rate to 1.811751250662785e-05
Epoch: 4 cost time: 1.6825790405273438
Epoch: 4, Steps: 38 | Train Loss: 0.4543409 Vali Loss: 0.4212809 Test Loss: 0.3255925
Validation loss decreased (0.447648 --> 0.421281).  Saving model ...
Updating learning rate to 2.8095736413660108e-05
Epoch: 5 cost time: 1.8823013305664062
Epoch: 5, Steps: 38 | Train Loss: 0.4420333 Vali Loss: 0.4085267 Test Loss: 0.3179923
Validation loss decreased (0.421281 --> 0.408527).  Saving model ...
Updating learning rate to 3.971012367723774e-05
Epoch: 6 cost time: 1.9022798538208008
Epoch: 6, Steps: 38 | Train Loss: 0.4343813 Vali Loss: 0.4030844 Test Loss: 0.3155189
Validation loss decreased (0.408527 --> 0.403084).  Saving model ...
Updating learning rate to 5.2165710052561655e-05
Epoch: 7 cost time: 1.7721500396728516
Epoch: 7, Steps: 38 | Train Loss: 0.4298231 Vali Loss: 0.4015156 Test Loss: 0.3129196
Validation loss decreased (0.403084 --> 0.401516).  Saving model ...
Updating learning rate to 6.460995415353218e-05
Epoch: 8 cost time: 2.0616672039031982
Epoch: 8, Steps: 38 | Train Loss: 0.4264621 Vali Loss: 0.4020291 Test Loss: 0.3125795
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.619109093311602e-05
Epoch: 9 cost time: 1.7941327095031738
Epoch: 9, Steps: 38 | Train Loss: 0.4241612 Vali Loss: 0.3972606 Test Loss: 0.3186591
Validation loss decreased (0.401516 --> 0.397261).  Saving model ...
Updating learning rate to 8.611643202601575e-05
Epoch: 10 cost time: 1.704589605331421
Epoch: 10, Steps: 38 | Train Loss: 0.4235956 Vali Loss: 0.3872763 Test Loss: 0.3140795
Validation loss decreased (0.397261 --> 0.387276).  Saving model ...
Updating learning rate to 9.370662249880032e-05
Epoch: 11 cost time: 1.677626371383667
Epoch: 11, Steps: 38 | Train Loss: 0.4228352 Vali Loss: 0.3915200 Test Loss: 0.3187893
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.844214032244276e-05
Epoch: 12 cost time: 1.5792617797851562
Epoch: 12, Steps: 38 | Train Loss: 0.4219625 Vali Loss: 0.3869154 Test Loss: 0.3141704
Validation loss decreased (0.387276 --> 0.386915).  Saving model ...
Updating learning rate to 9.999978205121845e-05
Epoch: 13 cost time: 1.6572115421295166
Epoch: 13, Steps: 38 | Train Loss: 0.4212326 Vali Loss: 0.3904255 Test Loss: 0.3156693
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.966886581024968e-05
Epoch: 14 cost time: 1.782341480255127
Epoch: 14, Steps: 38 | Train Loss: 0.4204256 Vali Loss: 0.3920408 Test Loss: 0.3245695
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.871333727828585e-05
Epoch: 15 cost time: 1.674523115158081
Epoch: 15, Steps: 38 | Train Loss: 0.4201737 Vali Loss: 0.3926658 Test Loss: 0.3268487
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.714521278102699e-05
Epoch: 16 cost time: 1.6142363548278809
Epoch: 16, Steps: 38 | Train Loss: 0.4193541 Vali Loss: 0.3896049 Test Loss: 0.3267199
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.498421239387314e-05
Epoch: 17 cost time: 1.7290434837341309
Epoch: 17, Steps: 38 | Train Loss: 0.4185359 Vali Loss: 0.3899971 Test Loss: 0.3292348
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.225751195053438e-05
Epoch: 18 cost time: 1.7425544261932373
Epoch: 18, Steps: 38 | Train Loss: 0.4175824 Vali Loss: 0.3901225 Test Loss: 0.3367629
EarlyStopping counter: 6 out of 10
Updating learning rate to 8.899940129115418e-05
Epoch: 19 cost time: 1.9994492530822754
Epoch: 19, Steps: 38 | Train Loss: 0.4170969 Vali Loss: 0.3869710 Test Loss: 0.3343679
EarlyStopping counter: 7 out of 10
Updating learning rate to 8.525085304767403e-05
Epoch: 20 cost time: 1.6340208053588867
Epoch: 20, Steps: 38 | Train Loss: 0.4149024 Vali Loss: 0.3903860 Test Loss: 0.3449382
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.105900738921409e-05
Epoch: 21 cost time: 1.7899670600891113
Epoch: 21, Steps: 38 | Train Loss: 0.4157865 Vali Loss: 0.3950137 Test Loss: 0.3418779
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.6476579207095e-05
Epoch: 22 cost time: 1.7047452926635742
Epoch: 22, Steps: 38 | Train Loss: 0.4154110 Vali Loss: 0.3987285 Test Loss: 0.3381506
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : Exchange_96_96_PatchTST_orthoConv_custom_ftM_sl96_ll48_pl336_dm128_nh16_el2_dl1_df256_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1182
mse:0.31417039036750793, mae:0.4034242033958435, rse:0.4366963803768158
